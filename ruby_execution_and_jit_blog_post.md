# How Ruby Executes Your Code: From Interpreter to JIT and Back

When you run Ruby code with JIT compilers (ZJIT or YJIT) enabled, it doesn't execute the same way throughout your application's lifetime. Ruby seamlessly switches between two execution modes: interpreting YARV bytecode and running native machine code generated by a JIT compiler.

This post focuses on how Ruby executes code, not how it compiles it. We'll explore three key execution flows:

1. **Pure Interpretation** - How Ruby executes bytecode when JIT is disabled or before methods are compiled
2. **Interpreter → JIT Transition** - The moment Ruby jumps from interpreting bytecode to executing native machine code
3. **JIT → Interpreter Fallback** - How and why JIT code returns control to the interpreter (deoptimization)

While we use ZJIT (Ruby's experimental next-generation JIT) as our reference, these execution patterns apply equally to YJIT.

## Ruby's Building Blocks: ISEQs and Bytecode

This post assumes basic familiarity with how interpreters and compilers work. In Ruby's case, your source code is first compiled to YARV bytecode, which the interpreter executes one by one.

A JIT compiler can then translate frequently-used bytecode into native machine code that runs directly on your CPU. If you're new to bytecode or want to dive deeper into YARV instructions, I highly recommend [Kevin Newton's Advent of YARV series](https://kddnewton.com/2022/11/30/advent-of-yarv-part-0.html).

### From Ruby Code to Bytecode

When Ruby loads your code, it doesn't execute the source directly. Instead, each method is compiled into an Instruction Sequence (ISEQ) - a data structure containing YARV instructions that the Ruby VM can execute.

Let's look at a simple example:

```ruby
def foo
  bar()
end

def bar
  42
end
```

Running `ruby --dump=insn example.rb` shows us the bytecode:

```text
== disasm: #<ISeq:foo@example.rb:1 (1,0)-(3,3)>
0000 putself                                                          (   2)[LiCa]
0001 opt_send_without_block                 <calldata!mid:bar, argc:0, FCALL|VCALL|ARGS_SIMPLE>
0003 leave                                  [Re]

== disasm: #<ISeq:bar@example.rb:5 (5,0)-(7,3)>
0000 putobject                              42                        (   6)[LiCa]
0002 leave                                  [Re]
```

Each method becomes its own ISEQ with a sequence of bytecode instructions. The `foo` method has three instructions:

- `putself` - pushes `self` onto the stack
- `opt_send_without_block` - send method call to `bar`, without passing a Ruby block
- `leave` - returns from the method

## Flow 1: Pure Interpreter Execution

When JIT is disabled or a method hasn't been compiled yet, Ruby executes bytecode through the interpreter. This is the baseline execution mode.

### The Interpreter Loop

The heart of Ruby's interpreter is `vm_exec_core()`, which implements a classic fetch-decode-execute loop:

1. **Fetch** - Read the next bytecode instruction at the current program counter
2. **Decode** - Determine what operation to perform
3. **Execute** - Perform the operation (might modify stack, call methods, etc.)
4. **Advance** - Move program counter to next instruction

This continues until the method returns or calls another method.

### Method Calls in Detail

When the interpreter encounters a method call like `opt_send_without_block`, here's what happens:

```text
┌─────────────────────────────────────────────────────┐
│              Interpreter Loop                        │
│                                                      │
│  Executing: [opt_send_without_block :bar]            │
│                    ↓                                 │
│         Method call handling:                        │
│           1. Look up method 'bar'                    │
│           2. Set up bar() for execution              │
│           3. Signal "method ready"                   │
│                    ↓                                 │
│          JIT_EXEC check                              │
│           - Check if bar has JIT code                │
│           - In this case: no JIT code                │
│           - Continue interpreting                    │
│                    ↓                                 │
│        Continue with bar's bytecode                  │
└─────────────────────────────────────────────────────┘
```

The key insight: method calls involve two steps - first setting up the method, then checking whether to execute it as bytecode or JIT code.

### The JIT_EXEC Check

Even in pure interpreter mode, Ruby always checks for JIT code after setting up a method call:

```c
// After opt_send_without_block
// 1. Set up the method call
// 2. Check if we should jump to JIT code
JIT_EXEC();  // Always runs, even without JIT enabled
```

The `JIT_EXEC` logic (simplified):

```text
if (method_was_called && method_has_jit_code) {
    jump_to_jit_code();
} else {
    continue_interpreting();
}
```

When there's no JIT compilation:

- Checks if the method has a `jit_entry` (pointer to compiled code)
- Finds NULL (no compiled code)
- Continues with interpreter

### Method Returns

The `leave` instruction handles returns:

1. Clean up the current method's state
2. Pass the return value to the caller
3. Continue executing in the caller

The interpreter maintains full control throughout this process.

So far, we've seen Ruby checking for JIT code but never finding any. What happens when those checks finally succeed? Let's explore how Ruby transitions from interpreting bytecode to executing native machine code.

## Flow 2: Interpreter → JIT Transition

Now let's see what happens when a method has been JIT-compiled and the interpreter needs to transition to native code.

### The JIT_EXEC Gateway

Remember the `JIT_EXEC` check we saw in Flow 1? It appeared after every method call setup, always checking for JIT code even when none existed. Now, this same check becomes the gateway to native code.

When a method has been JIT-compiled, the check finally finds something:

```text
JIT_EXEC logic (method has JIT code):
if (method_was_set_up && method_has_jit_code) {
    jump_to_native_code();
}
```

The difference from Flow 1? The second condition is now true - `jit_compile()` finds actual compiled code at the method's `jit_entry` pointer instead of NULL.

### How Methods Get JIT Compiled

Methods don't start with JIT code. They earn it through usage. ZJIT uses a two-phase approach:

```c
if (body->jit_entry == NULL && rb_zjit_enabled_p) {
    body->jit_entry_calls++;

    // At profile-threshold, rewrite some of the YARV instructions
    // to zjit_* instructions to profile these instructions.
    if (body->jit_entry_calls == rb_zjit_profile_threshold) {
        rb_zjit_profile_enable(iseq);
    }

    // At call-threshold, compile the ISEQ with ZJIT.
    if (body->jit_entry_calls == rb_zjit_call_threshold) {
        rb_zjit_compile_iseq(iseq, false);
    }
}
```

This two-phase approach allows the JIT to:

1. Profile execution patterns before compilation (e.g. understand the arguments' types at runtime)
2. Generate optimized code based on actual runtime behavior

Here's how a typical method evolves from interpreted to JIT-compiled:

```text
Method 'calculate' lifecycle:

Calls:     0 ──────── 25 ──────── 30 ─────────────────►
           │          │           │
Mode:      └─Interpret┴─Profile──┴─Native Code (JIT compiled)

Timeline:  Cold start  Gathering  Optimization complete,
                      type info   executing native code
```

Key thresholds (ZJIT defaults, may change in the future):

- **Profile threshold**: 25 calls - Start gathering type information
- **Compile threshold**: 30 calls - Generate optimized native code
- **Steady state**: 30+ calls - Execute compiled code

This is why JIT compilers need time to "warm up" to reach optimal speed - they need to observe your code's behavior before optimizing it.

And to learn more about how ZJIT compiles Ruby code, I recommend reading [ZJIT has been merged into Ruby](https://railsatscale.com/2025-05-14-merge-zjit/).

### Where JIT Code Lives

I used to think that JIT-compiled code would replace the bytecode as it's "faster", "better optimized"...etc. But it's actually not true - it lives alongside it in the ISEQ structure. Here's what an ISEQ looks like internally:

```text
ISEQ (foo method)
├── body
│   ├── bytecode: [putself, opt_send_without_block, leave]
│   ├── jit_entry: NULL  // Initially no JIT code
│   └── jit_entry_calls: 0  // Call counter
```

After a method is called enough times and gets JIT-compiled:

```text
ISEQ (foo method)
├── body
│   ├── bytecode: [putself, opt_send_without_block, leave]  // Still here!
│   ├── jit_entry: 0x7f8b2c001000  // Pointer to native machine code
│   └── jit_entry_calls: 1000  // Reached compilation threshold
```

The `jit_entry` field is the gateway to native code. When it's NULL, Ruby interprets bytecode. When it points to compiled code, Ruby jumps directly to machine instructions.

Now that we understand how Ruby code becomes bytecode and where JIT code lives, let's see how Ruby actually executes this code.

### The Transition Sequence

Let's trace through an actual interpreter-to-JIT transition:

```text
Interpreter executing foo() [not JITted]:

1. Executes: opt_send_without_block :bar

2. Method call setup:
   - Looks up bar method
   - Prepares bar for execution
   - Returns signal value

3. JIT_EXEC check runs

4. JIT check finds compiled code:
   - Gets bar's ISEQ
   - Checks iseq->body->jit_entry
   - Finds 0x7f8b2c001000 (pointer to compiled code)
   - Returns this function pointer

5. Direct jump to native code:
   - Call function at 0x7f8b2c001000
   - CPU executes compiled instructions
   - No more bytecode interpretation
```

### Visual: ISEQ State During Transition

Before the call to bar:

```text
ISEQ (bar)
├── body
│   ├── jit_entry: 0x7f8b2c001000  ← JIT code exists!
│   ├── jit_entry_calls: 1000       ← Reached threshold
│   └── bytecode: [putobject 42, leave]  ← Still available
```

During the transition:

```text
Method:              Execution Mode:
foo()          →     Interpreter (executing opt_send_without_block)
     ↓
bar()          →     JIT (about to execute native code at 0x7f8b2c001000)
```

The transition is remarkably simple - it's just a function pointer call. The interpreter jumps directly to the machine code address stored in `jit_entry`.

### What Happens in JIT Code

Once execution transfers to JIT code, native CPU instructions execute directly. Here's a glimpse of what the `bar` method looks like after JIT compilation (ARM64 assembly):

```asm
# bb0(v0): block in <main>@/tmp/test_jit.rb:6
0x1200c0084: stp x29, x30, [sp, #-0x10]!
0x1200c0088: mov x29, sp

# Guard: check object class matches expected type
0x1200c00a0: tst x0, #7
0x1200c00a4: b.ne #0x1200c0188     # side exit if guard fails (we'll explore this in Flow 3)

# Direct method call to 'bar' (no method lookup!)
0x1200c00e4: stur x0, [x21]
0x1200c00e8: ldr x1, #0x1200c00f0
0x1200c00f8: stur x1, [x21, #8]

# Push new control frame
0x1200c011c: stur x1, [x19, #-0x28]
0x1200c0120: stur x0, [x19, #-0x20]
```

Key differences from interpreter execution:

- Native CPU instructions execute directly
- No instruction fetch/decode overhead
- Guards ensure type safety with conditional branches
- Direct jumps to other JIT code (no method lookup)
- Register allocation instead of stack manipulation

The JIT code has full access to the Ruby VM's data structures and can:

- Call other JITted methods directly
- Fall back to the interpreter when needed (via side exits)
- Manipulate VM state just like the interpreter would

JIT code executes efficiently with its optimized assumptions and type guards. But what happens when those assumptions prove wrong? Ruby needs a way to gracefully fall back to the interpreter. Let's see how deoptimization ensures your code always runs correctly.

## Flow 3: JIT → Interpreter (Deoptimization)

JIT code can't always continue executing natively. When it encounters situations it can't handle, it gracefully returns control to the interpreter. The most common reason is guard failures.

### Type Guards and Optimized Code

JIT compilers optimize code by making assumptions. Consider this method:

```ruby
def add(a, b)
  a + b
end
```

The bytecode uses `opt_plus`:

```text
== disasm: #<ISeq:add@-e:1 (1,0)-(1,25)>
0000 getlocal_WC_0                          a@0
0002 getlocal_WC_0                          b@1
0004 opt_plus                               <calldata!mid:+, argc:1>
0006 leave
```

When ZJIT compiles this method after profiling shows it's always called with Fixnums (small integers), it generates optimized code:

```c
// Simplified representation of what ZJIT generates:
// 1. Type guard for 'a'
if (!FIXNUM_P(a)) goto side_exit;

// 2. Type guard for 'b'
if (!FIXNUM_P(b)) goto side_exit;

// 3. Fast path: direct integer addition
result = INT2FIX(FIX2INT(a) + FIX2INT(b));
return result;
```

The JIT inserts type guards using instructions like:

```rust
Insn::GuardType { val, guard_type: types::Fixnum, state }
```

### Guard Failure Flow

What happens when assumptions break:

```ruby
# First 30 calls - guards pass
add(1, 2)      # Both Fixnums ✓
add(5, 10)     # Both Fixnums ✓

# Call 31 - guard fails!
add(1.5, 2)    # 1.5 is Float, not Fixnum ✗
```

When the type guard fails:

```text
JIT Code (add method):
├─ Load 'a' (value: 1.5)
├─ Check: is 'a' Fixnum?
│  └─ NO! It's a Float
├─ Jump to side exit ←── Deoptimization starts here
│
Side Exit:
├─ Restore interpreter state:
│  ├─ Update stack pointer
│  ├─ Update instruction pointer
│  └─ Signal "need interpreter"
└─ Return to interpreter
```

### The VM_EXEC Return Path

When JIT code returns control to the interpreter, it uses the `VM_EXEC` logic:

```text
VM_EXEC logic:
if (jit_returned_special_value) {
    mark_for_interpreter_execution();
    return_to_interpreter();
}
```

The process:

1. JIT returns a special value signaling "need interpreter"
2. Set flags for interpreter execution
3. Call `vm_exec()` to continue in interpreter mode

### Visual: Complete Deoptimization Flow

```text
Initial State:
  JIT executing add(1.5, 2)
         ↓
Type Guard Check:
  FIXNUM_P(1.5) → false
         ↓
Side Exit:
  ├─ Save registers
  ├─ Restore instruction pointer to opt_plus
  ├─ Restore stack state
  └─ Signal "need interpreter"
         ↓
VM_EXEC logic:
  Check for special return value
  Call vm_exec() to re-enter interpreter
         ↓
Interpreter:
  Executes opt_plus with Float + Fixnum
  (slower but correct path)
```

### Other Deoptimization Triggers

Besides type guards, JIT returns to interpreter for:

- **Calling non-JITted methods** - If the target method hasn't been compiled
- **Unsupported bytecode**
- **Redefined core methods (BOP)** - If someone redefines `+` on Integer
- **TracePoint activation** - When TracePoint is enabled, Ruby falls back to executing the bytecode only to make sure TracePoint events are properly triggered
- **Ractor activation** - Some operations, like reading class/module's instance variables, have different behaviour under multi-ractor environments. So when a non-main ractor is spawned, JIT compilers would deoptimize related code as well.

The key insight: deoptimization isn't failure - it's a normal part of Ruby's execution strategy. The VM seamlessly handles the transition, ensuring your code always runs correctly even when optimistic assumptions prove wrong.

With all three execution flows understood - pure interpretation, transitioning to JIT, and falling back via deoptimization - we can now appreciate the elegant dance Ruby performs behind the scenes.

## Takeaways

Understanding Ruby's execution flow reveals three key insights:

1. **JIT code lives alongside bytecode, not replacing it** - Every ISEQ maintains both its original bytecode and a `jit_entry` pointer to native code. The `JIT_EXEC` check after every method call decides which to execute.

2. **Transitions are seamless and bidirectional** - Ruby can jump from interpreter to JIT (via function pointer), and JIT can return to interpreter (via side exits). Both happen automatically without your code knowing.

3. **Guards enable optimization without sacrificing correctness** - JIT code makes assumptions (like "this will be a Fixnum") protected by guards. When assumptions break, deoptimization ensures your code still runs correctly, just interpreted.

The next time your Ruby application runs in production with JIT enabled, you'll know exactly how it's transitioning between interpreted bytecode and native machine code - potentially thousands of times per second, all transparently managed by the Ruby VM.
